{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Armita Bahrudi - 810100591"]},{"cell_type":"markdown","metadata":{"id":"d0W-WuYsjWPP"},"source":["Artificial Intelligence - CA#02: *Reinforcement Learning* - fall 1402 \\\n","In this notebook, we will implement some reinforcement learning algorithms."]},{"cell_type":"markdown","metadata":{"id":"ksnYjMyNPAcn"},"source":["# Table of Contents\n","\n","- [Part 1: Value Iteration & Policy Iteration Algorithms](#1)\n","    - [َQuestion 1:](#1-0)\n","    - [َQuestion 2:](#1-1)\n","    - [َQuestion 3:](#1-12)\n","    - [َQuestion 4:](#1-2)\n","    - [َQuestion 5:](#1-3)\n","        - [Value Iteration](#1-3-1)\n","        - [Policy Iteration](#1-3-2)\n","    - [َQuestion 6:](#1-4)\n","        - [Value Iteration](#1-4-1)\n","        - [Policy Iteration](#1-4-2)\n","- [Part 2: Q-Learning Algorithm](#2)\n","    - [Question 7:](#2-1)\n","    - [َQuestion 8:](#2-2)\n","    - [َQuestion 9:](#2-3)\n","    - [َQuestion 10:](#2-4)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"dpTWKluXMHP5"},"outputs":[],"source":["# import\n","from IPython.display import clear_output\n","import matplotlib.pyplot as plt\n","from time import sleep\n","import numpy as np\n","import termtables\n","import random\n","import gym"]},{"cell_type":"markdown","metadata":{"id":"EifP8FUKLXE7"},"source":["<a name='1'></a>\n","## Part 1: Value Iteration & Policy Iteration Algorithms"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8LizJeOYRMEq"},"outputs":[],"source":["env = gym.make('FrozenLake-v1',render_mode = \"ansi\", desc=None, map_name=\"4x4\", is_slippery=False)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZARu6LDSqj_","outputId":"2f22167b-c6ef-493d-bec3-264a93e5d8cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["you can see the environment in each step by render command :\n","\n","\u001b[41mS\u001b[0mFFF\n","FHFH\n","FFFH\n","HFFG\n","\n"]}],"source":["# get familiar with the environment\n","print(\"you can see the environment in each step by render command :\")\n","env.reset()\n","print(env.render())"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x5QTTUSrSM-L","outputId":"206e612c-52ca-49d4-91b8-31f9faf5f1bc"},"outputs":[{"data":{"text/plain":["16"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Total no. of states\n","env.observation_space.n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EeaBqUeZSNNY","outputId":"46e8a041-a1e4-4e43-c22a-4e2c1a3a3ddc"},"outputs":[{"data":{"text/plain":["4"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Total no. of actions\n","env.action_space.n"]},{"cell_type":"markdown","metadata":{"id":"iVJmGmCUnIGR"},"source":["<a name='1-0'></a>\n","### Question 1:"]},{"cell_type":"markdown","metadata":{},"source":["an algorithm used to solve RL problems, where we have full knowledge of all components of the MDP. It works by iteratively improving its estimate of the 'value' of being in each state."]},{"cell_type":"markdown","metadata":{"id":"MO24LtBGLXZ7"},"source":["<a name='1-1'></a>\n","### Question 2:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VKP8LjK5jGoW"},"outputs":[],"source":["class ValueIteration():\n","    def __init__(self, env, discount_factor, theta=1e-8):\n","        self.env = env\n","        self.discount_factor = discount_factor\n","        self.theta = theta\n","        self.reset()\n","        self.state_values = np.ones((self.env.observation_space.n)) / self.env.action_space.n\n","        self.q_values = np.ones((self.env.observation_space.n, self.env.action_space.n)) / self.env.action_space.n\n","        self.state_values[self.env.observation_space.n - 1] = 0\n","        self.q_values[self.env.observation_space.n - 1] = np.zeros((self.env.action_space.n))\n","\n","    def value_estimation(self):\n","        self.delta = np.inf\n","        it = 0\n","        while(self.delta > self.theta):\n","            it += 1\n","            self.delta = 0\n","\n","            for state in range(self.env.observation_space.n):\n","\n","                v = self.state_values[state]\n","\n","                for action in range(self.env.action_space.n):\n","                    action_value = 0\n","                    for probability, next_state, reward, done in self.env.P[state][action]:\n","                         action_value += probability * (reward + (self.discount_factor * self.state_values[next_state]))\n","                    self.q_values[state, action] = action_value\n","\n","                self.state_values[state] = np.max(self.q_values[state,:])\n","\n","                self.delta = np.max([self.delta, abs(v - self.state_values[state])])\n","\n","                if (self.delta < self.theta):\n","                    break\n","        return it\n","\n","    def take_action(self, action):\n","        next_state, reward, done, _, _ = self.env.step(action)\n","        return next_state, reward, done\n","\n","    def get_optimal_policy(self, state):\n","        return np.argmax(self.q_values[state,:])\n","\n","    def get_state_values(self):\n","        return self.state_values\n","\n","    def get_q_values(self):\n","        return self.q_values\n","\n","    def reset(self):\n","        initial_state = self.env.reset()\n","        return initial_state"]},{"cell_type":"markdown","metadata":{"id":"frjc5mR4ncm1"},"source":["<a name='1-12'></a>\n","### Question 3:"]},{"cell_type":"markdown","metadata":{"id":"AMJJpf1tnddF"},"source":["Policy Iteration is one of the Model-Based reinforcement learning algorithms. In each iteration, the policy iteration function goes through two phases. One phase evaluates the policy, and the other one improves it."]},{"cell_type":"markdown","metadata":{"id":"V4DcH5yJLXqH"},"source":["<a name='1-2'></a>\n","### Question 4:"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1698433256083,"user":{"displayName":"Mohammad Saadati","userId":"00242434153251678664"},"user_tz":-210},"id":"XjSb1lX147hd"},"outputs":[],"source":["class PolicyIteration():\n","    def __init__(self, env, discount_factor, theta=1e-8):\n","        self.env = env\n","        self.discount_factor = discount_factor\n","        self.theta = theta\n","        self.reset()\n","        self.state_values = np.ones((self.env.observation_space.n)) / self.env.action_space.n\n","        self.q_values = np.ones((self.env.observation_space.n, self.env.action_space.n)) / self.env.action_space.n\n","        self.state_values[self.env.observation_space.n - 1] = 0\n","        self.q_values[self.env.observation_space.n - 1] = np.zeros((self.env.action_space.n))\n","        self.policy = np.random.randint(self.env.action_space.n, size=self.env.observation_space.n) # initial policy\n","        self.policy_stable = False\n","\n","    def policy_evaluation(self):\n","        self.delta = np.inf\n","\n","        while(self.delta >= self.theta):\n","\n","            self.delta = 0\n","\n","            for state in range(self.env.observation_space.n):\n","\n","                v = self.state_values[state]\n","\n","                new_state_value = 0\n","                for probability, next_state, reward, done in self.env.P[state][self.policy[state]]:\n","                    new_state_value += probability * (reward + self.discount_factor * self.state_values[next_state] )\n","                self.state_values[state] = new_state_value\n","\n","                self.delta = np.max([self.delta, abs(v - self.state_values[state])])\n","\n","    def policy_improvement(self):\n","        self.policy_stable = True\n","\n","        for state in range(self.env.observation_space.n):\n","            old_policy = self.policy[state]\n","\n","            for action in range(self.env.action_space.n):\n","\n","                action_value = 0\n","                for probability, next_state, reward, done in self.env.P[state][action]:\n","                    action_value += probability * (reward + self.discount_factor * self.state_values[next_state])\n","                self.q_values[state, action] = action_value\n","\n","            self.policy[state] = np.argmax(self.q_values[state,:])\n","\n","            if old_policy != self.policy[state]:\n","                self.policy_stable = False\n","\n","    def policy_estimation(self):\n","        self.policy_stable = False\n","        it = 0\n","        while not self.policy_stable:\n","            self.policy_evaluation()\n","            self.policy_improvement()\n","            it += 1\n","        return it\n","\n","    def take_action(self, action):\n","        next_state, reward, done, _, _ = self.env.step(action)\n","        return next_state, reward, done\n","\n","    def get_optimal_policy(self, state):\n","        return self.policy[state]\n","\n","    def get_state_values(self):\n","        return self.state_values\n","\n","    def get_q_values(self):\n","        return self.q_values\n","\n","    def reset(self):\n","        initial_state = self.env.reset()\n","        return initial_state"]},{"cell_type":"markdown","metadata":{"id":"u4G-kVjmLYj4"},"source":["<a name='1-3'></a>\n","### Question 5:"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["num_of_episodes = 100\n","discounting_factor = 0.9\n","FROZE_LAKE_ACTS = [\"LEFT\", \"DOWN\", \"RIGHT\", \"UP\"]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def print_frames(frames):\n","    for _, frame in enumerate(frames):\n","        clear_output(wait=True)\n","        print(frame['frame'])\n","        print(f\"Action: {frame['action']}\")\n","        print(f\"Reward: {frame['reward']}\")\n","        sleep(.5)\n","\n","def print_result(agent):\n","    q_table = agent.get_q_values()\n","    val_table = np.reshape(agent.get_state_values() , (-1, 4))\n","    optimal_policy = [FROZE_LAKE_ACTS[agent.get_optimal_policy(i)] for i in range(16)]\n","    policy_table = np.reshape(optimal_policy, (-1, 4))\n","    print(q_table)\n","    termtables.print(val_table)\n","    termtables.print(policy_table)"]},{"cell_type":"markdown","metadata":{"id":"PB651-ZY4vjE"},"source":["<a name='1-3-1'></a>\n","#### Value Iteration:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"RGYLOfYAuKjY"},"outputs":[{"name":"stdout","output_type":"stream","text":["it does 7 iteration in average to converge\n","[[0.531441   0.59049    0.59049    0.531441  ]\n"," [0.531441   0.13286025 0.6561     0.59049   ]\n"," [0.59049    0.729      0.59049    0.6561    ]\n"," [0.6561     0.13286025 0.59049    0.59049   ]\n"," [0.59049    0.6561     0.13286025 0.531441  ]\n"," [0.13286025 0.13286025 0.13286025 0.13286025]\n"," [0.11957423 0.81       0.13286025 0.6561    ]\n"," [0.13286025 0.13286025 0.13286025 0.13286025]\n"," [0.6561     0.13286025 0.729      0.59049   ]\n"," [0.6561     0.81       0.81       0.11957423]\n"," [0.729      0.9        0.13286025 0.729     ]\n"," [0.13286025 0.13286025 0.13286025 0.13286025]\n"," [0.13286025 0.13286025 0.13286025 0.13286025]\n"," [0.11957423 0.81       0.9        0.729     ]\n"," [0.81       0.9        1.         0.81      ]\n"," [0.         0.         0.         0.        ]]\n","┌─────────────────────┬─────────────────────┬────────────────────┬─────────────────────┐\n","│ 0.5904900000000002  │ 0.6561000000000001  │ 0.7290000000000001 │ 0.6561000000000001  │\n","├─────────────────────┼─────────────────────┼────────────────────┼─────────────────────┤\n","│ 0.6561000000000001  │ 0.13286025000000004 │ 0.81               │ 0.13286025000000004 │\n","├─────────────────────┼─────────────────────┼────────────────────┼─────────────────────┤\n","│ 0.7290000000000001  │ 0.81                │ 0.9                │ 0.13286025000000004 │\n","├─────────────────────┼─────────────────────┼────────────────────┼─────────────────────┤\n","│ 0.13286025000000004 │ 0.9                 │ 1.0                │ 0.0                 │\n","└─────────────────────┴─────────────────────┴────────────────────┴─────────────────────┘\n","┌───────┬───────┬───────┬──────┐\n","│ DOWN  │ RIGHT │ DOWN  │ LEFT │\n","├───────┼───────┼───────┼──────┤\n","│ DOWN  │ LEFT  │ DOWN  │ LEFT │\n","├───────┼───────┼───────┼──────┤\n","│ RIGHT │ DOWN  │ DOWN  │ LEFT │\n","├───────┼───────┼───────┼──────┤\n","│ LEFT  │ RIGHT │ RIGHT │ LEFT │\n","└───────┴───────┴───────┴──────┘\n"]},{"name":"stderr","output_type":"stream","text":["/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n","  if not isinstance(terminated, (bool, np.bool8)):\n"]}],"source":["def run_VI_episodes():\n","    tot_iterations = 0\n","    for _ in range(num_of_episodes):\n","        done = False\n","        value_iterator = ValueIteration(env= env, discount_factor=discounting_factor)\n","        state, _ = value_iterator.reset()\n","        tot_iterations += value_iterator.value_estimation()\n","        while not done:\n","            action = value_iterator.get_optimal_policy(state=state)\n","            next_state, _, done = value_iterator.take_action(action=action)\n","            state = next_state\n","    print(\"it does %i iteration in average to converge\" %(tot_iterations / num_of_episodes))\n","    return value_iterator\n","            \n","\n","value_iterator = run_VI_episodes()\n","print_result(value_iterator)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  (Right)\n","SFFF\n","FHFH\n","FFFH\n","HFF\u001b[41mG\u001b[0m\n","\n","Action: 2\n","Reward: 1.0\n"]}],"source":["frames = []\n","rewards = 0\n","frames.append({'frame': env.render(),'reward': rewards,'action': 0})\n","state, _ = value_iterator.reset()\n","done = False\n","i = 0\n","while not done:\n","    action = value_iterator.get_optimal_policy(state)\n","    next_state, reward, done = value_iterator.take_action(action)\n","    state = next_state\n","    rewards += reward\n","    frames.append({'frame': env.render(),'reward': rewards,'action': action})\n","    if done:\n","        break\n","print_frames(frames)\n"]},{"cell_type":"markdown","metadata":{"id":"ipZlzoXH40Mn"},"source":["<a name='1-3-2'></a>\n","#### Policy Iteration:"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"7Vxf_xKc44QT"},"outputs":[{"name":"stdout","output_type":"stream","text":["it does 6 iteration in average to converge\n","[[5.31441000e-01 5.90490000e-01 5.90490000e-01 5.31441000e-01]\n"," [5.31441000e-01 2.24536249e-08 6.56100000e-01 5.90490000e-01]\n"," [5.90490000e-01 7.29000000e-01 5.90490000e-01 6.56100000e-01]\n"," [6.56100000e-01 2.24536249e-08 5.90490000e-01 5.90490000e-01]\n"," [5.90490000e-01 6.56100000e-01 2.24536249e-08 5.31441000e-01]\n"," [2.24536249e-08 2.24536249e-08 2.24536249e-08 2.24536249e-08]\n"," [2.24536249e-08 8.10000000e-01 2.24536249e-08 6.56100000e-01]\n"," [2.24536249e-08 2.24536249e-08 2.24536249e-08 2.24536249e-08]\n"," [6.56100000e-01 2.24536249e-08 7.29000000e-01 5.90490000e-01]\n"," [6.56100000e-01 8.10000000e-01 8.10000000e-01 2.24536249e-08]\n"," [7.29000000e-01 9.00000000e-01 2.24536249e-08 7.29000000e-01]\n"," [2.24536249e-08 2.24536249e-08 2.24536249e-08 2.24536249e-08]\n"," [2.24536249e-08 2.24536249e-08 2.24536249e-08 2.24536249e-08]\n"," [2.24536249e-08 8.10000000e-01 9.00000000e-01 7.29000000e-01]\n"," [8.10000000e-01 9.00000000e-01 1.00000000e+00 8.10000000e-01]\n"," [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n","┌───────────────────────┬───────────────────────┬────────────────────┬───────────────────────┐\n","│ 0.5904900000000002    │ 0.6561000000000001    │ 0.7290000000000001 │ 0.6561000000000001    │\n","├───────────────────────┼───────────────────────┼────────────────────┼───────────────────────┤\n","│ 0.6561000000000001    │ 2.494847205842783e-08 │ 0.81               │ 2.494847205842783e-08 │\n","├───────────────────────┼───────────────────────┼────────────────────┼───────────────────────┤\n","│ 0.7290000000000001    │ 0.81                  │ 0.9                │ 2.494847205842783e-08 │\n","├───────────────────────┼───────────────────────┼────────────────────┼───────────────────────┤\n","│ 2.494847205842783e-08 │ 0.9                   │ 1.0                │ 0.0                   │\n","└───────────────────────┴───────────────────────┴────────────────────┴───────────────────────┘\n","┌───────┬───────┬───────┬──────┐\n","│ DOWN  │ RIGHT │ DOWN  │ LEFT │\n","├───────┼───────┼───────┼──────┤\n","│ DOWN  │ LEFT  │ DOWN  │ LEFT │\n","├───────┼───────┼───────┼──────┤\n","│ RIGHT │ DOWN  │ DOWN  │ LEFT │\n","├───────┼───────┼───────┼──────┤\n","│ LEFT  │ RIGHT │ RIGHT │ LEFT │\n","└───────┴───────┴───────┴──────┘\n"]}],"source":["def run_PI_episodes():\n","    tot_iterations = 0\n","    for _ in range(num_of_episodes):\n","        done = False\n","        policy_iterator = PolicyIteration(env= env, discount_factor=discounting_factor)\n","        state, _ = policy_iterator.reset()\n","        tot_iterations += policy_iterator.policy_estimation()\n","        while not done:\n","            action = policy_iterator.get_optimal_policy(state=state)\n","            next_state, _, done = policy_iterator.take_action(action=action)\n","            state = next_state\n","    print(\"it does %i iteration in average to converge\" %(tot_iterations / num_of_episodes))\n","    return policy_iterator\n","            \n","policy_iterator = run_PI_episodes()\n","print_result(policy_iterator)\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  (Right)\n","SFFF\n","FHFH\n","FFFH\n","HFF\u001b[41mG\u001b[0m\n","\n","Action: 2\n","Reward: 1.0\n"]}],"source":["frames = []\n","rewards = 0\n","frames.append({'frame': env.render(),'reward': rewards,'action': 0})\n","state, _ = policy_iterator.reset()\n","done = False\n","i = 0\n","while not done:\n","    action = policy_iterator.get_optimal_policy(state)\n","    next_state, reward, done = policy_iterator.take_action(action)\n","    state = next_state\n","    rewards += reward\n","    frames.append({'frame': env.render(),'reward': rewards,'action': action})\n","    if done:\n","        break\n","print_frames(frames)"]},{"cell_type":"markdown","metadata":{"id":"A3fnAFqJLpVI"},"source":["<a name='1-4'></a>\n","### Question 6:"]},{"cell_type":"markdown","metadata":{},"source":["Both methods give us the same policy, but the state values ​​obtained from policy iteration are much smaller than value iteration. As you can see in the output, Policy iteration converges faster."]},{"cell_type":"markdown","metadata":{"id":"hLtPLm-ELpG9"},"source":["<a name='2'></a>\n","## Part 2: Q-Learning Algorithm"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3cW_rkeDMOE8"},"outputs":[],"source":["# hyperparameters\n","REPS = 20\n","EPISODES = 200\n","EPSILON = 0.1\n","LEARNING_RATE = 0.3\n","DISCOUNT = 0.9\n","STUDENT_NUM = 591"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"L1c1w7tRMOR_"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-09 22:38:38.860 Python[3601:149542] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"]}],"source":["# environment\n","env = gym.make('Taxi-v3', render_mode = \"human\")\n","Initial_State = env.reset(seed= STUDENT_NUM)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"-8tJoWefMOdT"},"outputs":[{"name":"stdout","output_type":"stream","text":["you can see the environment in each step by render command :\n","None\n"]}],"source":["# get familiar with the environment\n","print(\"you can see the environment in each step by render command :\")\n","print(env.render())"]},{"cell_type":"markdown","metadata":{},"source":["<a name='2-1'></a>\n","### Question 7:"]},{"cell_type":"markdown","metadata":{},"source":["Q-learning is a model-free reinforcement learning algorithm to learn the value of an action in a particular state. It can handle problems with stochastic transitions and rewards without requiring adaptations."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"mQCB-ZIfNwJM"},"outputs":[{"data":{"text/plain":["500"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Total no. of states\n","env.observation_space.n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"lmk_EYbKNwYT"},"outputs":[{"data":{"text/plain":["6"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Total no. of actions\n","env.action_space.n"]},{"cell_type":"markdown","metadata":{"id":"oZJAP4nMLpiZ"},"source":["<a name='2-2'></a>\n","### Question 8:"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":503,"status":"ok","timestamp":1698434549406,"user":{"displayName":"Mohammad Saadati","userId":"00242434153251678664"},"user_tz":-210},"id":"Ue4m5fg9450B"},"outputs":[],"source":["class QLearningAgent():\n","    def __init__(self, env, epsilon, learning_rate, discount_factor, seed):\n","      self.env = env\n","      self.epsilon = epsilon\n","      self.learning_rate = learning_rate\n","      self.olr = learning_rate\n","      self.discount_factor = discount_factor\n","      self.q_table = np.zeros((env.observation_space.n, env.action_space.n))\n","      self.seed = seed\n","\n","    def choose_action(self, state):\n","      if random.uniform(0, 1) <= self.epsilon:\n","        action = random.randint(0, 5)\n","      else:\n","        action = self.get_optimal_policy( state)\n","      return action\n","\n","    def update_q_table(self, state, action, nextState, reward):\n","      self.q_table[state][action] += LEARNING_RATE * (reward + self.discount_factor * np.max(self.q_table[nextState]) - self.q_table[state][action])\n","\n","    def decay_epsilon(self, episode):\n","      self.epsilon = EPSILON ** episode\n","\n","    def decrease_learning_rate(self, episode):\n","      self.learning_rate = 1000/(1000 + episode) * LEARNING_RATE\n","\n","    def take_action(self, action):\n","      next_state, reward, done, _ , _ = self.env.step(action)\n","      return next_state, reward, done\n","\n","    def get_optimal_policy(self, state):\n","      return np.argmax(self.q_table[state])\n","\n","    def get_q_values(self):\n","      return self.q_table\n","\n","    def reset(self):\n","      return self.env.reset(seed=self.seed)"]},{"cell_type":"markdown","metadata":{"id":"c5HFAMk-Lpvs"},"source":["<a name='2-3'></a>\n","### Question 9:"]},{"cell_type":"markdown","metadata":{},"source":["According to the execution time of the two pieces of code and the graphs, it can be said that in the case where the learning rate decreases, we converge to the answer a little earlier. /\n","Regarding the function used to reduce the learning rate, exponential, linear, and $$ fitness =  1  /  (1 + {episodes}) * learning\\_rate $$ functions have also been tested."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"qgRhXXmwo6MT"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n","  if not isinstance(terminated, (bool, np.bool8)):\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     11\u001b[0m     action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mchoose_action(state)\n\u001b[0;32m---> 12\u001b[0m     next_state, reward, done \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     agent\u001b[38;5;241m.\u001b[39mupdate_q_table(state,action,next_state,reward)\n\u001b[1;32m     14\u001b[0m     rewards \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n","Cell \u001b[0;32mIn[19], line 28\u001b[0m, in \u001b[0;36mQLearningAgent.take_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtake_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m---> 28\u001b[0m   next_state, reward, done, _ , _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m next_state, reward, done\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/wrappers/time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/envs/toy_text/taxi.py:262\u001b[0m, in \u001b[0;36mTaxiEnv.step\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlastaction \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mint\u001b[39m(s), r, t, \u001b[38;5;28;01mFalse\u001b[39;00m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m\"\u001b[39m: p, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_mask(s)})\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/envs/toy_text/taxi.py:290\u001b[0m, in \u001b[0;36mTaxiEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_text()\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# self.render_mode in {\"human\", \"rgb_array\"}:\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_gui\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gym/envs/toy_text/taxi.py:416\u001b[0m, in \u001b[0;36mTaxiEnv._render_gui\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    415\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[1;32m    419\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(pygame\u001b[38;5;241m.\u001b[39msurfarray\u001b[38;5;241m.\u001b[39mpixels3d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow)), axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    420\u001b[0m     )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["fix_episodes = []\n","fix_rewards = []\n","for rep in range(REPS):\n","    agent = QLearningAgent(env, EPSILON, LEARNING_RATE, DISCOUNT, STUDENT_NUM)\n","    state, _ = agent.reset()\n","    for episode in range(EPISODES):\n","        rewards = 0\n","        done = False\n","        Initial_state = env.reset(seed=STUDENT_NUM)\n","        while not done:\n","            action = agent.choose_action(state)\n","            next_state, reward, done = agent.take_action(action)\n","            agent.update_q_table(state,action,next_state,reward)\n","            rewards += reward\n","            state = next_state\n","            if done:\n","                break\n","        agent.decay_epsilon(episode)\n","        if rep == 0:\n","            fix_episodes.append(episode)\n","            fix_rewards.append(rewards)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dec_episodes = []\n","dec_rewards = []\n","for rep in range(REPS):\n","    agent = QLearningAgent(env, EPSILON, LEARNING_RATE, DISCOUNT, STUDENT_NUM)\n","    state, _ = agent.reset()\n","    for episode in range(EPISODES):\n","        rewards = 0\n","        done = False\n","        state, _ = agent.reset()\n","        while not done:\n","            action = agent.choose_action(state)\n","            next_state, reward, done = agent.take_action(action)\n","            agent.update_q_table(state,action,next_state,reward)\n","            rewards += reward\n","            state = next_state\n","            if done:\n","                break\n","        agent.decay_epsilon(episode)\n","        agent.decrease_learning_rate(episode)\n","        if rep == 0:\n","            dec_episodes.append(episode)\n","            dec_rewards.append(rewards)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.plot(fix_episodes, fix_rewards)\n","plt.plot(dec_episodes, dec_rewards)\n","\n","plt.xlabel('episode')\n","plt.ylabel('reward')\n","\n","plt.title('reward per episodes')\n","plt.grid()\n","plt.legend([\"Fix lr\", \"Decreasing lr\"])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"BVcMKEGDQWdU"},"source":["<a name='2-4'></a>\n","### Question 10:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FlHPV0kqQWdU"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------+\n","|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (Dropoff)\n","\n","Action: 5\n","Reward: 10\n"]}],"source":["state, _ = agent.reset()\n","done = False\n","rewards = 0\n","frames = []\n","Initial_state = env.reset(seed=STUDENT_NUM)\n","frames.append({'frame': env.render(),'reward': rewards,'action': 0})\n","while not done:\n","    action = agent.get_optimal_policy(state)\n","    next_state, reward, done = agent.take_action(action)\n","    state = next_state\n","    rewards += reward\n","    frames.append({'frame': env.render(),'reward': rewards,'action': action})\n","    if done:\n","        break\n","#print_frames(frames)"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
